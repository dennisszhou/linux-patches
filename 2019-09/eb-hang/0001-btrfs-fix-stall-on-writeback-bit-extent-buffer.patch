From 1a57b5ee6e52c63bf7c8e3ae969c0df406e3cf69 Mon Sep 17 00:00:00 2001
From: Dennis Zhou <dennis@kernel.org>
Date: Wed, 4 Sep 2019 10:49:53 -0700
Subject: [PATCH] btrfs: fix stall on writeback bit extent buffer

In lock_extent_buffer_for_io(), if we encounter a blocking action, we
try and flush the currently held onto bio. The failure mode here used to
be a BUG_ON(). f4340622e022 changed this to move BUG_ON() up and
incorrectly reset the current ret code. However,
lock_extent_buffer_for_io() returns 1 on we should write out the pages.
This caused the buffer to be skipped while keeping the writeback bit
set.

Now that we can fail here, we also need to fix up dirty_metadata_bytes,
clear BTRFS_HEADER_FLAG_WRITTEN and EXTENT_BUFFER_WRITEBACK, and set
EXTENT_BUFFER_DIRTY again.

Fixes: f4340622e022 ("btrfs: extent_io: Move the BUG_ON() in flush_write_bio() one level up")
Signed-off-by: Dennis Zhou <dennis@kernel.org>
---
 fs/btrfs/extent_io.c | 52 ++++++++++++++++++++++++++++++++++++--------
 1 file changed, 43 insertions(+), 9 deletions(-)

diff --git a/fs/btrfs/extent_io.c b/fs/btrfs/extent_io.c
index 43af8245c06e..4ba3cd972a2a 100644
--- a/fs/btrfs/extent_io.c
+++ b/fs/btrfs/extent_io.c
@@ -3636,6 +3636,13 @@ void wait_on_extent_buffer_writeback(struct extent_buffer *eb)
 		       TASK_UNINTERRUPTIBLE);
 }
 
+static void end_extent_buffer_writeback(struct extent_buffer *eb)
+{
+	clear_bit(EXTENT_BUFFER_WRITEBACK, &eb->bflags);
+	smp_mb__after_atomic();
+	wake_up_bit(&eb->bflags, EXTENT_BUFFER_WRITEBACK);
+}
+
 /*
  * Lock eb pages and flush the bio if we can't the locks
  *
@@ -3707,9 +3714,11 @@ static noinline_for_stack int lock_extent_buffer_for_io(struct extent_buffer *eb
 
 		if (!trylock_page(p)) {
 			if (!flush) {
-				ret = flush_write_bio(epd);
-				if (ret < 0) {
+				int flush_ret = flush_write_bio(epd);
+
+				if (flush_ret < 0) {
 					failed_page_nr = i;
+					ret = flush_ret;
 					goto err_unlock;
 				}
 				flush = 1;
@@ -3723,24 +3732,45 @@ static noinline_for_stack int lock_extent_buffer_for_io(struct extent_buffer *eb
 	/* Unlock already locked pages */
 	for (i = 0; i < failed_page_nr; i++)
 		unlock_page(eb->pages[i]);
-	return ret;
-}
 
-static void end_extent_buffer_writeback(struct extent_buffer *eb)
-{
-	clear_bit(EXTENT_BUFFER_WRITEBACK, &eb->bflags);
-	smp_mb__after_atomic();
-	wake_up_bit(&eb->bflags, EXTENT_BUFFER_WRITEBACK);
+	/* undo the above above because we failed */
+	btrfs_tree_lock(eb);
+
+	percpu_counter_add_batch(&fs_info->dirty_metadata_bytes,
+					 eb->len,
+					 fs_info->dirty_metadata_batch);
+
+	btrfs_clear_header_flag(eb, BTRFS_HEADER_FLAG_WRITTEN);
+
+	spin_lock(&eb->refs_lock);
+	set_bit(EXTENT_BUFFER_DIRTY, &eb->bflags);
+	spin_unlock(&eb->refs_lock);
+
+	btrfs_tree_unlock(eb);
+
+	end_extent_buffer_writeback(eb);
+
+	return ret;
 }
 
 static void set_btree_ioerr(struct page *page)
 {
 	struct extent_buffer *eb = (struct extent_buffer *)page->private;
+	struct btrfs_fs_info *fs_info;
 
 	SetPageError(page);
 	if (test_and_set_bit(EXTENT_BUFFER_WRITE_ERR, &eb->bflags))
 		return;
 
+	/*
+	 * We just marked the extent as bad, that means we need retry
+	 * in the future, so fix up the dirty_metadata_bytes accounting.
+	 */
+	fs_info = eb->fs_info;
+	percpu_counter_add_batch(&fs_info->dirty_metadata_bytes,
+				 eb->len,
+				 fs_info->dirty_metadata_batch);
+
 	/*
 	 * If writeback for a btree extent that doesn't belong to a log tree
 	 * failed, increment the counter transaction->eb_write_errors.
@@ -3977,6 +4007,10 @@ int btree_write_cache_pages(struct address_space *mapping,
 			if (!ret) {
 				free_extent_buffer(eb);
 				continue;
+			} else if (ret < 0) {
+				done = 1;
+				free_extent_buffer(eb);
+				break;
 			}
 
 			ret = write_one_eb(eb, wbc, &epd);
-- 
2.17.1

